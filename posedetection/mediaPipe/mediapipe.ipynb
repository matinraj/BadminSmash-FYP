{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Extracting Landmark </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radian = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radian*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Mediapipe for Video </h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THIS ONLY FOR DATA COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../PoseVideos/LCW_Cropped-5.mp4\")\n",
    "crop_rate = 3\n",
    "under_arm_degree = 30\n",
    "# Mediapipe Instance\n",
    "with mp_pose.Pose(static_image_mode = False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    last_pose = \"Unknown\"\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recoloring Image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "            left_elbow =  [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            # Angles\n",
    "            left_arm = calculateAngle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_arm = calculateAngle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            left_leg = calculateAngle(left_hip, left_knee, left_ankle)\n",
    "            right_leg = calculateAngle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "            left_under_arm = calculateAngle(left_elbow, left_shoulder, left_hip)\n",
    "            right_under_arm = calculateAngle(right_elbow, right_shoulder, right_hip)\n",
    "\n",
    "            if (165 <= right_under_arm <= 180):\n",
    "               last_pose = \"Smash\"\n",
    "\n",
    "            else:\n",
    "                cv2.putText(image, last_pose, [20, 20], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            x, y, z = image.shape\n",
    "\n",
    "            if right_under_arm > under_arm_degree and count % crop_rate == 0:\n",
    "                try:\n",
    "                    os.mkdir(\"created\")\n",
    "                except:\n",
    "                    pass\n",
    "                img_path = \"created\"\n",
    "\n",
    "                \n",
    "                img_name = 'cropped_' + str(count) + '.png'\n",
    "                img_path = os.path.join(img_path, img_name )\n",
    "                cv2.imwrite(img_path, image)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        # Render Detection\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('MediaPipe', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MediaPipe for Image </h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS SECTION IS FOR COLLECTING DATA FROM IMAGES THAT HAS BEEN CLASSIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderDirs = ['backhand', 'forehand', 'netdrop', 'serve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/backhand/cropped_1035.png\n",
      "data/backhand/cropped_1040.png\n",
      "data/backhand/cropped_1071.png\n",
      "data/backhand/cropped_1074.png\n",
      "data/backhand/cropped_1224.png\n",
      "data/backhand/cropped_1227.png\n",
      "data/backhand/cropped_1230.png\n",
      "data/backhand/cropped_1233.png\n",
      "data/backhand/cropped_1287.png\n",
      "data/backhand/cropped_1290.png\n",
      "data/backhand/cropped_1293.png\n",
      "data/backhand/cropped_1296.png\n",
      "data/backhand/cropped_1299.png\n",
      "data/backhand/cropped_1377.png\n",
      "data/backhand/cropped_1380.png\n",
      "data/backhand/cropped_189.png\n",
      "data/backhand/cropped_190.png\n",
      "data/backhand/cropped_192.png\n",
      "data/backhand/cropped_195.png\n",
      "data/backhand/cropped_2030.png\n",
      "data/backhand/cropped_2035.png\n",
      "data/backhand/cropped_204.png\n",
      "data/backhand/cropped_207.png\n",
      "data/backhand/cropped_210.png\n",
      "data/backhand/cropped_243.png\n",
      "data/backhand/cropped_246.png\n",
      "data/backhand/cropped_249.png\n",
      "data/backhand/cropped_2613.png\n",
      "data/backhand/cropped_2616.png\n",
      "data/backhand/cropped_2619.png\n",
      "data/backhand/cropped_2622.png\n",
      "data/backhand/cropped_3081.png\n",
      "data/backhand/cropped_3084.png\n",
      "data/backhand/cropped_3822.png\n",
      "data/backhand/cropped_3825.png\n",
      "data/backhand/cropped_3828.png\n",
      "data/backhand/cropped_402.png\n",
      "data/backhand/cropped_4040.png\n",
      "data/backhand/cropped_4045.png\n",
      "data/backhand/cropped_405.png\n",
      "data/backhand/cropped_4071.png\n",
      "data/backhand/cropped_4074.png\n",
      "data/backhand/cropped_4077.png\n",
      "data/backhand/cropped_4080.png\n",
      "data/backhand/cropped_4323.png\n",
      "data/backhand/cropped_4326.png\n",
      "data/backhand/cropped_4329.png\n",
      "data/backhand/cropped_4332.png\n",
      "data/backhand/cropped_4875.png\n",
      "data/backhand/cropped_4880.png\n",
      "data/backhand/cropped_5115.png\n",
      "data/backhand/cropped_516.png\n",
      "data/backhand/cropped_519.png\n",
      "data/backhand/cropped_522.png\n",
      "data/backhand/cropped_5225.png\n",
      "data/backhand/cropped_5260.png\n",
      "data/backhand/cropped_5265.png\n",
      "data/backhand/cropped_5320.png\n",
      "data/backhand/cropped_5325.png\n",
      "data/backhand/cropped_600.png\n",
      "data/backhand/cropped_603.png\n",
      "data/backhand/cropped_606.png\n",
      "data/backhand/cropped_732.png\n",
      "data/backhand/cropped_735.png\n",
      "data/backhand/cropped_738.png\n",
      "data/backhand/cropped_741.png\n",
      "data/backhand/cropped_768.png\n",
      "data/backhand/cropped_771.png\n",
      "data/backhand/cropped_774.png\n",
      "data/backhand/cropped_777.png\n",
      "data/backhand/cropped_885.png\n",
      "data/backhand/cropped_890.png\n",
      "data/forehand/cropped_1026.png\n",
      "data/forehand/cropped_1029.png\n",
      "data/forehand/cropped_1032.png\n",
      "data/forehand/cropped_1050.png\n",
      "data/forehand/cropped_1188.png\n",
      "data/forehand/cropped_1270.png\n",
      "data/forehand/cropped_1370.png\n",
      "data/forehand/cropped_1375.png\n",
      "data/forehand/cropped_1446.png\n",
      "data/forehand/cropped_1449.png\n",
      "data/forehand/cropped_1452.png\n",
      "data/forehand/cropped_1455.png\n",
      "data/forehand/cropped_1464.png\n",
      "data/forehand/cropped_1467.png\n",
      "data/forehand/cropped_150.png\n",
      "data/forehand/cropped_1503.png\n",
      "data/forehand/cropped_1506.png\n",
      "data/forehand/cropped_1520.png\n",
      "data/forehand/cropped_1525.png\n",
      "data/forehand/cropped_1560.png\n",
      "data/forehand/cropped_1566.png\n",
      "data/forehand/cropped_160.png\n",
      "data/forehand/cropped_165.png\n",
      "data/forehand/cropped_1767.png\n",
      "data/forehand/cropped_1773.png\n",
      "data/forehand/cropped_1795.png\n",
      "data/forehand/cropped_1800.png\n",
      "data/forehand/cropped_1851.png\n",
      "data/forehand/cropped_1854.png\n",
      "data/forehand/cropped_1915.png\n",
      "data/forehand/cropped_1920.png\n",
      "data/forehand/cropped_1925.png\n",
      "data/forehand/cropped_2070.png\n",
      "data/forehand/cropped_2076.png\n",
      "data/forehand/cropped_2079.png\n",
      "data/forehand/cropped_2082.png\n",
      "data/forehand/cropped_2109 copy.png\n",
      "data/forehand/cropped_2109.png\n",
      "data/forehand/cropped_2112 copy.png\n",
      "data/forehand/cropped_2112.png\n",
      "data/forehand/cropped_2115.png\n",
      "data/forehand/cropped_2124.png\n",
      "data/forehand/cropped_2127.png\n",
      "data/forehand/cropped_213.png\n",
      "data/forehand/cropped_216.png\n",
      "data/forehand/cropped_2180.png\n",
      "data/forehand/cropped_2185.png\n",
      "data/forehand/cropped_2220.png\n",
      "data/forehand/cropped_225.png\n",
      "data/forehand/cropped_226.png\n",
      "data/forehand/cropped_2274.png\n",
      "data/forehand/cropped_2277.png\n",
      "data/forehand/cropped_2280.png\n",
      "data/forehand/cropped_2283.png\n",
      "data/forehand/cropped_2286.png\n",
      "data/forehand/cropped_230.png\n",
      "data/forehand/cropped_2301.png\n",
      "data/forehand/cropped_2304.png\n",
      "data/forehand/cropped_2328.png\n",
      "data/forehand/cropped_2331.png\n",
      "data/forehand/cropped_2334.png\n",
      "data/forehand/cropped_2337.png\n",
      "data/forehand/cropped_2340.png\n",
      "data/forehand/cropped_2343.png\n",
      "data/forehand/cropped_235.png\n",
      "data/forehand/cropped_2385.png\n",
      "data/forehand/cropped_2395.png\n",
      "data/forehand/cropped_24.png\n",
      "data/forehand/cropped_2430.png\n",
      "data/forehand/cropped_2433.png\n",
      "data/forehand/cropped_2445 copy.png\n",
      "data/forehand/cropped_2445.png\n",
      "data/forehand/cropped_2448.png\n",
      "data/forehand/cropped_2450.png\n",
      "data/forehand/cropped_2460.png\n",
      "data/forehand/cropped_2463.png\n",
      "data/forehand/cropped_2493.png\n",
      "data/forehand/cropped_2496.png\n",
      "data/forehand/cropped_250.png\n",
      "data/forehand/cropped_255 copy.png\n",
      "data/forehand/cropped_255.png\n",
      "data/forehand/cropped_2560.png\n",
      "data/forehand/cropped_258.png\n",
      "data/forehand/cropped_2580.png\n",
      "data/forehand/cropped_260.png\n",
      "data/forehand/cropped_2649.png\n",
      "data/forehand/cropped_267.png\n",
      "data/forehand/cropped_2680.png\n",
      "data/forehand/cropped_2685.png\n",
      "data/forehand/cropped_27.png\n",
      "data/forehand/cropped_2755.png\n",
      "data/forehand/cropped_2835.png\n",
      "data/forehand/cropped_2847.png\n",
      "data/forehand/cropped_2850.png\n",
      "data/forehand/cropped_2853.png\n",
      "data/forehand/cropped_2859.png\n",
      "data/forehand/cropped_2862.png\n",
      "data/forehand/cropped_2865.png\n",
      "data/forehand/cropped_2970.png\n",
      "data/forehand/cropped_2973.png\n",
      "data/forehand/cropped_30.png\n",
      "data/forehand/cropped_3018.png\n",
      "data/forehand/cropped_3021.png\n",
      "data/forehand/cropped_3033.png\n",
      "data/forehand/cropped_3036.png\n",
      "data/forehand/cropped_3039.png\n",
      "data/forehand/cropped_3075.png\n",
      "data/forehand/cropped_3078.png\n",
      "data/forehand/cropped_3081.png\n",
      "data/forehand/cropped_3095.png\n",
      "data/forehand/cropped_3100.png\n",
      "data/forehand/cropped_3144 copy.png\n",
      "data/forehand/cropped_3144.png\n",
      "data/forehand/cropped_3147 copy.png\n",
      "data/forehand/cropped_3147.png\n",
      "data/forehand/cropped_3150 copy.png\n",
      "data/forehand/cropped_3150.png\n",
      "data/forehand/cropped_3153.png\n",
      "data/forehand/cropped_3183.png\n",
      "data/forehand/cropped_3250.png\n",
      "data/forehand/cropped_3255.png\n",
      "data/forehand/cropped_3305.png\n",
      "data/forehand/cropped_3310.png\n",
      "data/forehand/cropped_3315.png\n",
      "data/forehand/cropped_3320.png\n",
      "data/forehand/cropped_333.png\n",
      "data/forehand/cropped_336.png\n",
      "data/forehand/cropped_3375.png\n",
      "data/forehand/cropped_3378.png\n",
      "data/forehand/cropped_339.png\n",
      "data/forehand/cropped_3405.png\n",
      "data/forehand/cropped_3408.png\n",
      "data/forehand/cropped_3410.png\n",
      "data/forehand/cropped_3415.png\n",
      "data/forehand/cropped_342.png\n",
      "data/forehand/cropped_3420.png\n",
      "data/forehand/cropped_3425.png\n",
      "data/forehand/cropped_3513.png\n",
      "data/forehand/cropped_3516.png\n",
      "data/forehand/cropped_3519.png\n",
      "data/forehand/cropped_3522.png\n",
      "data/forehand/cropped_3525.png\n",
      "data/forehand/cropped_3528.png\n",
      "data/forehand/cropped_3531.png\n",
      "data/forehand/cropped_3534.png\n",
      "data/forehand/cropped_3558.png\n",
      "data/forehand/cropped_3561.png\n",
      "data/forehand/cropped_360.png\n",
      "data/forehand/cropped_3600.png\n",
      "data/forehand/cropped_3605.png\n",
      "data/forehand/cropped_361.png\n",
      "data/forehand/cropped_3648.png\n",
      "data/forehand/cropped_365.png\n",
      "data/forehand/cropped_3651.png\n",
      "data/forehand/cropped_3654.png\n",
      "data/forehand/cropped_3753.png\n",
      "data/forehand/cropped_3756.png\n",
      "data/forehand/cropped_3830.png\n",
      "data/forehand/cropped_3834.png\n",
      "data/forehand/cropped_3885.png\n",
      "data/forehand/cropped_3888.png\n",
      "data/forehand/cropped_3939.png\n",
      "data/forehand/cropped_3945.png\n",
      "data/forehand/cropped_3948.png\n",
      "data/forehand/cropped_3951.png\n",
      "data/forehand/cropped_3985.png\n",
      "data/forehand/cropped_3990.png\n",
      "data/forehand/cropped_4047.png\n",
      "data/forehand/cropped_4050.png\n",
      "data/forehand/cropped_4053.png\n",
      "data/forehand/cropped_4095.png\n",
      "data/forehand/cropped_4130.png\n",
      "data/forehand/cropped_4134.png\n",
      "data/forehand/cropped_4137.png\n",
      "data/forehand/cropped_4285.png\n",
      "data/forehand/cropped_4290.png\n",
      "data/forehand/cropped_4320.png\n",
      "data/forehand/cropped_4325.png\n",
      "data/forehand/cropped_4380.png\n",
      "data/forehand/cropped_4467.png\n",
      "data/forehand/cropped_4470.png\n",
      "data/forehand/cropped_4497.png\n",
      "data/forehand/cropped_4500.png\n",
      "data/forehand/cropped_4527.png\n",
      "data/forehand/cropped_4530.png\n",
      "data/forehand/cropped_4540.png\n",
      "data/forehand/cropped_456.png\n",
      "data/forehand/cropped_4575.png\n",
      "data/forehand/cropped_4578.png\n",
      "data/forehand/cropped_4680.png\n",
      "data/forehand/cropped_4683.png\n",
      "data/forehand/cropped_4701.png\n",
      "data/forehand/cropped_4704.png\n",
      "data/forehand/cropped_4707.png\n",
      "data/forehand/cropped_4720.png\n",
      "data/forehand/cropped_4722.png\n",
      "data/forehand/cropped_4749.png\n",
      "data/forehand/cropped_4775.png\n",
      "data/forehand/cropped_4780.png\n",
      "data/forehand/cropped_4800.png\n",
      "data/forehand/cropped_4803.png\n",
      "data/forehand/cropped_4806.png\n",
      "data/forehand/cropped_4845.png\n",
      "data/forehand/cropped_4848.png\n",
      "data/forehand/cropped_4851.png\n",
      "data/forehand/cropped_4854.png\n",
      "data/forehand/cropped_4930.png\n",
      "data/forehand/cropped_4960.png\n",
      "data/forehand/cropped_4962.png\n",
      "data/forehand/cropped_4965 copy.png\n",
      "data/forehand/cropped_4965.png\n",
      "data/forehand/cropped_5000.png\n",
      "data/forehand/cropped_5005.png\n",
      "data/forehand/cropped_5010.png\n",
      "data/forehand/cropped_5070.png\n",
      "data/forehand/cropped_51.png\n",
      "data/forehand/cropped_5103.png\n",
      "data/forehand/cropped_5106.png\n",
      "data/forehand/cropped_5135.png\n",
      "data/forehand/cropped_5140.png\n",
      "data/forehand/cropped_5185.png\n",
      "data/forehand/cropped_5190.png\n",
      "data/forehand/cropped_5244.png\n",
      "data/forehand/cropped_5247.png\n",
      "data/forehand/cropped_525.png\n",
      "data/forehand/cropped_5250.png\n",
      "data/forehand/cropped_5253.png\n",
      "data/forehand/cropped_5256.png\n",
      "data/forehand/cropped_5259.png\n",
      "data/forehand/cropped_530.png\n",
      "data/forehand/cropped_543.png\n",
      "data/forehand/cropped_546.png\n",
      "data/forehand/cropped_550.png\n",
      "data/forehand/cropped_591.png\n",
      "data/forehand/cropped_597.png\n",
      "data/forehand/cropped_624.png\n",
      "data/forehand/cropped_627.png\n",
      "data/forehand/cropped_633.png\n",
      "data/forehand/cropped_636.png\n",
      "data/forehand/cropped_639.png\n",
      "data/forehand/cropped_655.png\n",
      "data/forehand/cropped_693.png\n",
      "data/forehand/cropped_696.png\n",
      "data/forehand/cropped_735.png\n",
      "data/forehand/cropped_820.png\n",
      "data/forehand/cropped_825.png\n",
      "data/forehand/cropped_85.png\n",
      "data/forehand/cropped_87.png\n",
      "data/forehand/cropped_90 copy.png\n",
      "data/forehand/cropped_90.png\n",
      "data/forehand/cropped_912.png\n",
      "data/forehand/cropped_920.png\n",
      "data/forehand/cropped_924.png\n",
      "data/forehand/cropped_925.png\n",
      "data/forehand/cropped_927.png\n",
      "data/forehand/cropped_965.png\n",
      "data/forehand/cropped_993.png\n",
      "data/forehand/cropped_996.png\n",
      "data/forehand/cropped_999.png\n",
      "data/netdrop/cropped_105.png\n",
      "data/netdrop/cropped_106.png\n",
      "data/netdrop/cropped_1080.png\n",
      "data/netdrop/cropped_1083.png\n",
      "data/netdrop/cropped_1119.png\n",
      "data/netdrop/cropped_1122.png\n",
      "data/netdrop/cropped_1125.png\n",
      "data/netdrop/cropped_1128 copy.png\n",
      "data/netdrop/cropped_1128.png\n",
      "data/netdrop/cropped_1131 copy.png\n",
      "data/netdrop/cropped_1131.png\n",
      "data/netdrop/cropped_1134.png\n",
      "data/netdrop/cropped_1137.png\n",
      "data/netdrop/cropped_1145.png\n",
      "data/netdrop/cropped_1150.png\n",
      "data/netdrop/cropped_123.png\n",
      "data/netdrop/cropped_126.png\n",
      "data/netdrop/cropped_1310.png\n",
      "data/netdrop/cropped_1315.png\n",
      "data/netdrop/cropped_1344.png\n",
      "data/netdrop/cropped_1347.png\n",
      "data/netdrop/cropped_135 copy.png\n",
      "data/netdrop/cropped_135.png\n",
      "data/netdrop/cropped_1350.png\n",
      "data/netdrop/cropped_1353.png\n",
      "data/netdrop/cropped_1356.png\n",
      "data/netdrop/cropped_1359.png\n",
      "data/netdrop/cropped_1362.png\n",
      "data/netdrop/cropped_138 copy.png\n",
      "data/netdrop/cropped_138.png\n",
      "data/netdrop/cropped_141 copy.png\n",
      "data/netdrop/cropped_141.png\n",
      "data/netdrop/cropped_144 copy.png\n",
      "data/netdrop/cropped_144.png\n",
      "data/netdrop/cropped_147 copy.png\n",
      "data/netdrop/cropped_147.png\n",
      "data/netdrop/cropped_1491.png\n",
      "data/netdrop/cropped_1494.png\n",
      "data/netdrop/cropped_1497.png\n",
      "data/netdrop/cropped_150 copy.png\n",
      "data/netdrop/cropped_150.png\n",
      "data/netdrop/cropped_153.png\n",
      "data/netdrop/cropped_1551.png\n",
      "data/netdrop/cropped_156.png\n",
      "data/netdrop/cropped_1620.png\n",
      "data/netdrop/cropped_1625.png\n",
      "data/netdrop/cropped_1630.png\n",
      "data/netdrop/cropped_1635.png\n",
      "data/netdrop/cropped_170.png\n",
      "data/netdrop/cropped_1715.png\n",
      "data/netdrop/cropped_1720.png\n",
      "data/netdrop/cropped_1722.png\n",
      "data/netdrop/cropped_1725.png\n",
      "data/netdrop/cropped_1728.png\n",
      "data/netdrop/cropped_1731.png\n",
      "data/netdrop/cropped_1794.png\n",
      "data/netdrop/cropped_1797.png\n",
      "data/netdrop/cropped_180.png\n",
      "data/netdrop/cropped_1800.png\n",
      "data/netdrop/cropped_1803.png\n",
      "data/netdrop/cropped_1830.png\n",
      "data/netdrop/cropped_1872.png\n",
      "data/netdrop/cropped_1875.png\n",
      "data/netdrop/cropped_1878.png\n",
      "data/netdrop/cropped_1905.png\n",
      "data/netdrop/cropped_1959.png\n",
      "data/netdrop/cropped_1990.png\n",
      "data/netdrop/cropped_1995.png\n",
      "data/netdrop/cropped_2019.png\n",
      "data/netdrop/cropped_2025.png\n",
      "data/netdrop/cropped_2090.png\n",
      "data/netdrop/cropped_2172.png\n",
      "data/netdrop/cropped_2175.png\n",
      "data/netdrop/cropped_2178.png\n",
      "data/netdrop/cropped_2304.png\n",
      "data/netdrop/cropped_2307.png\n",
      "data/netdrop/cropped_2310.png\n",
      "data/netdrop/cropped_2313.png\n",
      "data/netdrop/cropped_2316.png\n",
      "data/netdrop/cropped_2319.png\n",
      "data/netdrop/cropped_2379.png\n",
      "data/netdrop/cropped_2382.png\n",
      "data/netdrop/cropped_2500.png\n",
      "data/netdrop/cropped_2505.png\n",
      "data/netdrop/cropped_2510.png\n",
      "data/netdrop/cropped_2511.png\n",
      "data/netdrop/cropped_2514.png\n",
      "data/netdrop/cropped_2517.png\n",
      "data/netdrop/cropped_2520.png\n",
      "data/netdrop/cropped_2550.png\n",
      "data/netdrop/cropped_2553.png\n",
      "data/netdrop/cropped_2556.png\n",
      "data/netdrop/cropped_2700.png\n",
      "data/netdrop/cropped_2763.png\n",
      "data/netdrop/cropped_2805.png\n",
      "data/netdrop/cropped_285 copy.png\n",
      "data/netdrop/cropped_285.png\n",
      "data/netdrop/cropped_288 copy.png\n",
      "data/netdrop/cropped_288.png\n",
      "data/netdrop/cropped_291 copy.png\n",
      "data/netdrop/cropped_291.png\n",
      "data/netdrop/cropped_2910.png\n",
      "data/netdrop/cropped_2913.png\n",
      "data/netdrop/cropped_2916.png\n",
      "data/netdrop/cropped_2925.png\n",
      "data/netdrop/cropped_2928.png\n",
      "data/netdrop/cropped_294.png\n",
      "data/netdrop/cropped_297.png\n",
      "data/netdrop/cropped_3048.png\n",
      "data/netdrop/cropped_3051.png\n",
      "data/netdrop/cropped_3054.png\n",
      "data/netdrop/cropped_3057.png\n",
      "data/netdrop/cropped_3132.png\n",
      "data/netdrop/cropped_3135.png\n",
      "data/netdrop/cropped_3138.png\n",
      "data/netdrop/cropped_3141.png\n",
      "data/netdrop/cropped_3333.png\n",
      "data/netdrop/cropped_3336.png\n",
      "data/netdrop/cropped_3339.png\n",
      "data/netdrop/cropped_3342.png\n",
      "data/netdrop/cropped_3372.png\n",
      "data/netdrop/cropped_3375.png\n",
      "data/netdrop/cropped_3378.png\n",
      "data/netdrop/cropped_3585.png\n",
      "data/netdrop/cropped_3636.png\n",
      "data/netdrop/cropped_3639.png\n",
      "data/netdrop/cropped_3685.png\n",
      "data/netdrop/cropped_3690.png\n",
      "data/netdrop/cropped_4131.png\n",
      "data/netdrop/cropped_4134.png\n",
      "data/netdrop/cropped_4137.png\n",
      "data/netdrop/cropped_4140.png\n",
      "data/netdrop/cropped_4143.png\n",
      "data/netdrop/cropped_4146.png\n",
      "data/netdrop/cropped_4152.png\n",
      "data/netdrop/cropped_4245.png\n",
      "data/netdrop/cropped_447.png\n",
      "data/netdrop/cropped_450.png\n",
      "data/netdrop/cropped_4554.png\n",
      "data/netdrop/cropped_4563.png\n",
      "data/netdrop/cropped_4566.png\n",
      "data/netdrop/cropped_4569.png\n",
      "data/netdrop/cropped_4572.png\n",
      "data/netdrop/cropped_4578.png\n",
      "data/netdrop/cropped_459.png\n",
      "data/netdrop/cropped_4626.png\n",
      "data/netdrop/cropped_4821.png\n",
      "data/netdrop/cropped_4824.png\n",
      "data/netdrop/cropped_4827.png\n",
      "data/netdrop/cropped_4830.png\n",
      "data/netdrop/cropped_4833.png\n",
      "data/netdrop/cropped_4836.png\n",
      "data/netdrop/cropped_4935.png\n",
      "data/netdrop/cropped_4956.png\n",
      "data/netdrop/cropped_4959.png\n",
      "data/netdrop/cropped_4995.png\n",
      "data/netdrop/cropped_4998.png\n",
      "data/netdrop/cropped_5001.png\n",
      "data/netdrop/cropped_5004.png\n",
      "data/netdrop/cropped_504.png\n",
      "data/netdrop/cropped_5055.png\n",
      "data/netdrop/cropped_507.png\n",
      "data/netdrop/cropped_510.png\n",
      "data/netdrop/cropped_513.png\n",
      "data/netdrop/cropped_516.png\n",
      "data/netdrop/cropped_5175.png\n",
      "data/netdrop/cropped_5193.png\n",
      "data/netdrop/cropped_5196.png\n",
      "data/netdrop/cropped_5199.png\n",
      "data/netdrop/cropped_5270.png\n",
      "data/netdrop/cropped_5275.png\n",
      "data/netdrop/cropped_5310.png\n",
      "data/netdrop/cropped_5313.png\n",
      "data/netdrop/cropped_5316.png\n",
      "data/netdrop/cropped_575.png\n",
      "data/netdrop/cropped_595.png\n",
      "data/netdrop/cropped_600.png\n",
      "data/netdrop/cropped_601.png\n",
      "data/netdrop/cropped_609.png\n",
      "data/netdrop/cropped_615.png\n",
      "data/netdrop/cropped_696.png\n",
      "data/netdrop/cropped_699.png\n",
      "data/netdrop/cropped_702.png\n",
      "data/netdrop/cropped_810.png\n",
      "data/netdrop/cropped_815.png\n",
      "data/netdrop/cropped_880.png\n",
      "data/netdrop/cropped_90.png\n",
      "data/netdrop/cropped_909.png\n",
      "data/netdrop/cropped_912.png\n",
      "data/netdrop/cropped_915.png\n",
      "data/netdrop/cropped_918.png\n",
      "data/netdrop/cropped_93.png\n",
      "data/netdrop/cropped_96.png\n",
      "data/netdrop/cropped_99.png\n",
      "data/serve/cropped_0.png\n",
      "data/serve/cropped_1008.png\n",
      "data/serve/cropped_1011.png\n",
      "data/serve/cropped_1014.png\n",
      "data/serve/cropped_1389.png\n",
      "data/serve/cropped_1392.png\n",
      "data/serve/cropped_1395.png\n",
      "data/serve/cropped_1398.png\n",
      "data/serve/cropped_1401.png\n",
      "data/serve/cropped_1404.png\n",
      "data/serve/cropped_1407.png\n",
      "data/serve/cropped_1460.png\n",
      "data/serve/cropped_1465.png\n",
      "data/serve/cropped_1470.png\n",
      "data/serve/cropped_1701.png\n",
      "data/serve/cropped_1704.png\n",
      "data/serve/cropped_1707.png\n",
      "data/serve/cropped_1710.png\n",
      "data/serve/cropped_1713.png\n",
      "data/serve/cropped_1716.png\n",
      "data/serve/cropped_1719.png\n",
      "data/serve/cropped_1722.png\n",
      "data/serve/cropped_1725.png\n",
      "data/serve/cropped_1728.png\n",
      "data/serve/cropped_1749.png\n",
      "data/serve/cropped_20.png\n",
      "data/serve/cropped_2270.png\n",
      "data/serve/cropped_2275.png\n",
      "data/serve/cropped_2280.png\n",
      "data/serve/cropped_2285.png\n",
      "data/serve/cropped_2290.png\n",
      "data/serve/cropped_2295.png\n",
      "data/serve/cropped_2300.png\n",
      "data/serve/cropped_265.png\n",
      "data/serve/cropped_270.png\n",
      "data/serve/cropped_2709.png\n",
      "data/serve/cropped_2712.png\n",
      "data/serve/cropped_2715.png\n",
      "data/serve/cropped_2718.png\n",
      "data/serve/cropped_2721.png\n",
      "data/serve/cropped_2724.png\n",
      "data/serve/cropped_2727.png\n",
      "data/serve/cropped_2730.png\n",
      "data/serve/cropped_275.png\n",
      "data/serve/cropped_2871.png\n",
      "data/serve/cropped_2874.png\n",
      "data/serve/cropped_2877.png\n",
      "data/serve/cropped_2880.png\n",
      "data/serve/cropped_2883.png\n",
      "data/serve/cropped_3205.png\n",
      "data/serve/cropped_3210.png\n",
      "data/serve/cropped_3215.png\n",
      "data/serve/cropped_3220.png\n",
      "data/serve/cropped_3225.png\n",
      "data/serve/cropped_3230.png\n",
      "data/serve/cropped_3235.png\n",
      "data/serve/cropped_3240.png\n",
      "data/serve/cropped_3245.png\n",
      "data/serve/cropped_3255.png\n",
      "data/serve/cropped_3260.png\n",
      "data/serve/cropped_3261.png\n",
      "data/serve/cropped_3265.png\n",
      "data/serve/cropped_3270.png\n",
      "data/serve/cropped_3275.png\n",
      "data/serve/cropped_3276.png\n",
      "data/serve/cropped_3501.png\n",
      "data/serve/cropped_3504.png\n",
      "data/serve/cropped_3507.png\n",
      "data/serve/cropped_3597.png\n",
      "data/serve/cropped_3600.png\n",
      "data/serve/cropped_3603.png\n",
      "data/serve/cropped_3606.png\n",
      "data/serve/cropped_3609.png\n",
      "data/serve/cropped_3612.png\n",
      "data/serve/cropped_3615.png\n",
      "data/serve/cropped_3618.png\n",
      "data/serve/cropped_3621.png\n",
      "data/serve/cropped_3624.png\n",
      "data/serve/cropped_3627.png\n",
      "data/serve/cropped_3630.png\n",
      "data/serve/cropped_399.png\n",
      "data/serve/cropped_40.png\n",
      "data/serve/cropped_402.png\n",
      "data/serve/cropped_405.png\n",
      "data/serve/cropped_408.png\n",
      "data/serve/cropped_411.png\n",
      "data/serve/cropped_4225.png\n",
      "data/serve/cropped_4230.png\n",
      "data/serve/cropped_4251.png\n",
      "data/serve/cropped_4254.png\n",
      "data/serve/cropped_4257.png\n",
      "data/serve/cropped_4260.png\n",
      "data/serve/cropped_4263.png\n",
      "data/serve/cropped_4266.png\n",
      "data/serve/cropped_4420.png\n",
      "data/serve/cropped_4425.png\n",
      "data/serve/cropped_4430.png\n",
      "data/serve/cropped_4435.png\n",
      "data/serve/cropped_4440.png\n",
      "data/serve/cropped_4445.png\n",
      "data/serve/cropped_4450.png\n",
      "data/serve/cropped_4455.png\n",
      "data/serve/cropped_4460.png\n",
      "data/serve/cropped_4465.png\n",
      "data/serve/cropped_45.png\n",
      "data/serve/cropped_4632.png\n",
      "data/serve/cropped_4635.png\n",
      "data/serve/cropped_5073.png\n",
      "data/serve/cropped_5076.png\n",
      "data/serve/cropped_5079.png\n",
      "data/serve/cropped_5082.png\n",
      "data/serve/cropped_5085.png\n",
      "data/serve/cropped_5088.png\n",
      "data/serve/cropped_5091.png\n",
      "data/serve/cropped_5094.png\n",
      "data/serve/cropped_60.png\n",
      "data/serve/cropped_61.png\n",
      "data/serve/cropped_62.png\n",
      "data/serve/cropped_63.png\n",
      "data/serve/cropped_64.png\n",
      "data/serve/cropped_729.png\n",
      "data/serve/cropped_732.png\n",
      "data/serve/cropped_735.png\n",
      "data/serve/cropped_738.png\n",
      "data/serve/cropped_75.png\n",
      "data/serve/cropped_78.png\n",
      "data/serve/cropped_81.png\n",
      "data/serve/cropped_84.png\n"
     ]
    }
   ],
   "source": [
    "crop_rate = 15\n",
    "path = \"created/\"\n",
    "filler = \"data\"\n",
    "# Mediapipe Instance\n",
    "# left_shoulder, right_shoulder, left_elbow, right_elbow, left_wrist, right_wrist, left_hip, right_hip, left_knee, right_knee, left_ankle, right_ankle,\n",
    "f = open(\"data.csv\", \"w\")\n",
    "f.writelines(\"label, left_arm, right_arm, left_leg, right_leg, left_under_arm, right_under_arm\\n\")\n",
    "f.close()\n",
    "t = cv2.imread(\"backhand/cropped_1035.png\");\n",
    "with mp_pose.Pose(static_image_mode = True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    last_pose = \"Unknown\"\n",
    "    count = 0\n",
    "    for i in range(len(folderDirs)):\n",
    "        f = open(\"data.csv\", \"a\")\n",
    "        \n",
    "        for eaImg in os.listdir(filler + \"/\" +folderDirs[i] + \"/\"):\n",
    "            print(filler + \"/\" + folderDirs[i] + \"/\" + eaImg)\n",
    "            frame = cv2.imread(filler + \"/\" +folderDirs[i] + \"/\" + eaImg)\n",
    "            # ret, frame = cap.read()\n",
    "\n",
    "            # Recoloring Image\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make Detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Recolor back\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Extract\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "                left_elbow =  [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "\n",
    "                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "\n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "                # Angles\n",
    "                left_arm = calculateAngle(left_shoulder, left_elbow, left_wrist)\n",
    "                right_arm = calculateAngle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "                left_leg = calculateAngle(left_hip, left_knee, left_ankle)\n",
    "                right_leg = calculateAngle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "                left_under_arm = calculateAngle(left_elbow, left_shoulder, left_hip)\n",
    "                right_under_arm = calculateAngle(right_elbow, right_shoulder, right_hip)\n",
    "\n",
    "                f.writelines(str(folderDirs[i]) + \", \" +\n",
    "                             str(left_arm) + \", \" +\n",
    "                             str(right_arm) + \", \" +\n",
    "                             str(left_leg) + \", \" +\n",
    "                             str(right_leg) + \", \" +\n",
    "                             str(left_under_arm) + \", \" +\n",
    "                             str(right_under_arm) + \"\\n\")\n",
    "            except:\n",
    "                pass\n",
    "            # Render Detection\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # cv2.imshow('MediaPipe', image)\n",
    "            try:\n",
    "                os.mkdir(\"estimated\")\n",
    "            except:\n",
    "                pass\n",
    "            img_path = \"estimated\"\n",
    "            img_name = 'pose_' + str(count) + '.png'\n",
    "            img_path = os.path.join(img_path, img_name )\n",
    "            cv2.imwrite(img_path, image)\n",
    "            count += 1\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "f.close()\n",
    "\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predicting with Model </h1>\n",
    "<p> v01 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MODEL TO CHOOSE:<h3>\n",
    "<ul>\n",
    "<li style=\"font-size:16px\">badminton_modelv01.pkl : Initial Model that has 70% accuracy with less data</li>\n",
    "<li style=\"font-size:16px\">badminton_modelv02.pkl : 6 classifications: Forehand, Backhand, Serve, Smash, Netdrop, 67% accuracy using Random Forest Classification</li>\n",
    "<li style=\"font-size:16px\">badminton_modelv03.pkl : 3 classifications: Forehand, Backhand, Netdrop. 62% accuracy using Random Forest Classification.</li>\n",
    "<br>\n",
    "<li style=\"font-size:16px\">fillerv01.pkl: 5 Classifications, 60% - 64% max at 64.5% with RFC</li>\n",
    "<li style=\"font-size:16px\">fillervo2.pkl: 4 Classifications, constant of 67% with LR </li>\n",
    "<li style=\"font-size:16px\">fillerv03.pkl: 3 Classifications, RFC of 62% - 70% average of 65% using RFC</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('badminton_modelv03.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../PoseVideos/badminton2.mp4\")\n",
    "crop_rate = 5\n",
    "# Mediapipe Instance\n",
    "with mp_pose.Pose(static_image_mode = False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    last_pose = \"Unknown\"\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recoloring Image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "            left_elbow =  [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            # Angles\n",
    "            left_arm = calculateAngle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_arm = calculateAngle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            left_leg = calculateAngle(left_hip, left_knee, left_ankle)\n",
    "            right_leg = calculateAngle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "            left_under_arm = calculateAngle(left_elbow, left_shoulder, left_hip)\n",
    "            right_under_arm = calculateAngle(right_elbow, right_shoulder, right_hip)\n",
    "            # print(left_arm, right_arm, left_leg, right_leg, left_under_arm, right_under_arm)\n",
    "            lst = np.array([left_arm, right_arm, left_leg, right_leg, left_under_arm, right_under_arm]).flatten()\n",
    "            lst = list(lst)\n",
    "            x = pd.DataFrame([lst])\n",
    "            # if len(x.values[0]) < 6:\n",
    "            #     print(x)\n",
    "            # x = pd.DataFrame([left_arm, right_arm, left_leg, right_leg, left_under_arm, right_under_arm])\n",
    "            model_class = model.predict(x.values)[0]\n",
    "            model_prob = model.predict_proba(x.values)[0]\n",
    "            # # print(x)\n",
    "            \n",
    "            if(round(model_prob[np.argmax(model_prob)],2) > 0.7):\n",
    "\n",
    "                # Display Class\n",
    "                cv2.putText(image, model_class, [25, 25], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(image, \"Unknown\", [25, 25], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display Probability\n",
    "            cv2.putText(image, str(round(model_prob[np.argmax(model_prob)],2)), [35, 45], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        # Render Detection\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('MediaPipe', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
